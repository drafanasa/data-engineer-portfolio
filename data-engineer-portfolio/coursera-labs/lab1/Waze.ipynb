{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DtNBZFHO3M7n"
   },
   "source": [
    "# **Waze Project**\n",
    "**Course 2 - Get Started with Python**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zJCatj3xzrQZ"
   },
   "source": [
    "Welcome to the Waze Project!\n",
    "\n",
    "Your Waze data analytics team is still in the early stages of their user churn project. Previously, you were asked to complete a project proposal by your supervisor, May Santner. You have received notice that your project proposal has been approved and that your team has been given access to Waze's user data. To get clear insights, the user data must be inspected and prepared for the upcoming process of exploratory data analysis (EDA).\n",
    "\n",
    "A Python notebook has been prepared to guide you through this project. Answer the questions and create an executive summary for the Waze data team."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rgSbVJvomcVa"
   },
   "source": [
    "# **Course 2 End-of-course project: Inspect and analyze data**\n",
    "\n",
    "In this activity, you will examine data provided and prepare it for analysis. This activity will help ensure the information is,\n",
    "\n",
    "1.   Ready to answer questions and yield insights\n",
    "\n",
    "2.   Ready for visualizations\n",
    "\n",
    "3.   Ready for future hypothesis testing and statistical methods\n",
    "<br/>\n",
    "\n",
    "**The purpose** of this project is to investigate and understand the data provided.\n",
    "\n",
    "**The goal** is to use a dataframe contructed within Python, perform a cursory inspection of the provided dataset, and inform team members of your findings.\n",
    "<br/>\n",
    "\n",
    "*This activity has three parts:*\n",
    "\n",
    "**Part 1:** Understand the situation\n",
    "* How can you best prepare to understand and organize the provided information?\n",
    "\n",
    "**Part 2:** Understand the data\n",
    "\n",
    "* Create a pandas dataframe for data learning, future exploratory data analysis (EDA), and statistical activities\n",
    "\n",
    "* Compile summary information about the data to inform next steps\n",
    "\n",
    "**Part 3:** Understand the variables\n",
    "\n",
    "* Use insights from your examination of the summary data to guide deeper investigation into variables\n",
    "\n",
    "\n",
    "<br/>\n",
    "\n",
    "Follow the instructions and answer the following questions to complete the activity. Then, you will complete an Executive Summary using the questions listed on the PACE Strategy Document.\n",
    "\n",
    "Be sure to complete this activity before moving on. The next course item will provide you with a completed exemplar to compare to your own work.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HjFGokxv2pc5"
   },
   "source": [
    "# **Identify data types and compile summary information**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MRUYfzCb4vop"
   },
   "source": [
    "<img src=\"images/Pace.png\" width=\"100\" height=\"100\" align=left>\n",
    "\n",
    "# **PACE stages**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b4B47DQPcSQu"
   },
   "source": [
    "Throughout these project notebooks, you'll see references to the problem-solving framework, PACE. The following notebook components are labeled with the respective PACE stages: Plan, Analyze, Construct, and Execute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zRHb2QQWj99m"
   },
   "source": [
    "<img src=\"images/Plan.png\" width=\"100\" height=\"100\" align=left>\n",
    "\n",
    "\n",
    "## **PACE: Plan**\n",
    "\n",
    "Consider the questions in your PACE Strategy Document and those below to craft your response:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pWEfG5zJV5oG"
   },
   "source": [
    "### **Task 1. Understand the situation**\n",
    "\n",
    "*   How can you best prepare to understand and organize the provided driver data?\n",
    "\n",
    "\n",
    "*Begin by exploring your dataset and consider reviewing the Data Dictionary.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "irvqnKSe6Z80"
   },
   "source": [
    "Review the Data Dictionary: This will help in understanding the meaning of each column, the data types, and the context of the data provided.\n",
    "\n",
    "Initial Data Exploration: Load the dataset into a pandas dataframe to inspect the first few rows and get an overview of the structure.\n",
    "\n",
    "Identify Data Types: Check the data types of each column to confirm they are appropriate for the type of data they contain. This will help in identifying any data type conversions needed.\n",
    "\n",
    "Check for Missing Values: Identify if there are any missing or null values that need to be addressed.\n",
    "\n",
    "Summarize Basic Statistics: Use descriptive statistics (mean, median, min, max, standard deviation) to understand data distribution and identify potential anomalies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1E9Y5aC0IAA-"
   },
   "source": [
    "<img src=\"images/Analyze.png\" width=\"100\" height=\"100\" align=left>\n",
    "\n",
    "## **PACE: Analyze**\n",
    "\n",
    "Consider the questions in your PACE Strategy Document to reflect on the Analyze stage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D4WK_AxP_S__"
   },
   "source": [
    "### **Task 2a. Imports and data loading**\n",
    "\n",
    "Start by importing the packages that you will need to load and explore the dataset. Make sure to use the following import statements:\n",
    "\n",
    "*   `import pandas as pd`\n",
    "\n",
    "*   `import numpy as np`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OZSXM4q5zrQh"
   },
   "outputs": [],
   "source": [
    "# Import packages for data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2-hT-EQA67v3"
   },
   "source": [
    "Then, load the dataset into a dataframe. Creating a dataframe will help you conduct data manipulation, exploratory data analysis (EDA), and statistical activities.\n",
    "\n",
    "**Note:** As shown in this cell, the dataset has been automatically loaded in for you. You do not need to download the .csv file, or provide more code, in order to access the dataset and proceed with this lab. Please continue with this activity by completing the following instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset into dataframe\n",
    "df = pd.read_csv('waze_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gYx1emvno7U_"
   },
   "source": [
    "### **Task 2b. Summary information**\n",
    "\n",
    "View and inspect summary information about the dataframe by **coding the following:**\n",
    "\n",
    "1.   df.head(10)\n",
    "2.   df.info()\n",
    "\n",
    "*Consider the following questions:*\n",
    "\n",
    "1. When reviewing the `df.head()` output, are there any variables that have missing values?\n",
    "\n",
    "2. When reviewing the `df.info()` output, what are the data types? How many rows and columns do you have?\n",
    "\n",
    "3. Does the dataset have any missing values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "t7Nck2hh4R6J"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'waze_dataset.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Load dataset into dataframe\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwaze_dataset.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m df\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m20\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'waze_dataset.csv'"
     ]
    }
   ],
   "source": [
    "# Import packages for data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Load dataset into dataframe\n",
    "df = pd.read_csv('waze_dataset.csv')\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3NctoTSAvGGD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14999 entries, 0 to 14998\n",
      "Data columns (total 13 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   ID                       14999 non-null  int64  \n",
      " 1   label                    14299 non-null  object \n",
      " 2   sessions                 14999 non-null  int64  \n",
      " 3   drives                   14999 non-null  int64  \n",
      " 4   total_sessions           14999 non-null  float64\n",
      " 5   n_days_after_onboarding  14999 non-null  int64  \n",
      " 6   total_navigations_fav1   14999 non-null  int64  \n",
      " 7   total_navigations_fav2   14999 non-null  int64  \n",
      " 8   driven_km_drives         14999 non-null  float64\n",
      " 9   duration_minutes_drives  14999 non-null  float64\n",
      " 10  activity_days            14999 non-null  int64  \n",
      " 11  driving_days             14999 non-null  int64  \n",
      " 12  device                   14999 non-null  object \n",
      "dtypes: float64(3), int64(8), object(2)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "### YOUR CODE HERE ###\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JscqNfr6ZVsE"
   },
   "source": [
    "ĐÁNH GIÁ:\n",
    "When reviewing the df.head() output, there 700 variables of 'label' column that have missing values\n",
    "When reviewing the df.info() output, the data types are: float64(3), int64(8), object(2), with 14999 rows and 13 columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BMNnIoc51_1N"
   },
   "source": [
    "### **Task 2c. Null values and summary statistics**\n",
    "\n",
    "Compare the summary statistics of the 700 rows that are missing labels with summary statistics of the rows that are not missing any values.\n",
    "\n",
    "**Question:** Is there a discernible difference between the two populations?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bAQeHW-d2S1-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Null rows mean:\n",
      "ID                         7405.584286\n",
      "label                              NaN\n",
      "sessions                     80.837143\n",
      "drives                       67.798571\n",
      "total_sessions              198.483348\n",
      "n_days_after_onboarding    1709.295714\n",
      "total_navigations_fav1      118.717143\n",
      "total_navigations_fav2       30.371429\n",
      "driven_km_drives           3935.967029\n",
      "duration_minutes_drives    1795.123358\n",
      "activity_days                15.382857\n",
      "driving_days                 12.125714\n",
      "dtype: float64\n",
      "\n",
      "Non-null rows mean:\n",
      "ID                         7503.573117\n",
      "sessions                     80.623820\n",
      "drives                       67.255822\n",
      "total_sessions              189.547409\n",
      "n_days_after_onboarding    1751.822505\n",
      "total_navigations_fav1      121.747395\n",
      "total_navigations_fav2       29.638296\n",
      "driven_km_drives           4044.401535\n",
      "duration_minutes_drives    1864.199794\n",
      "activity_days                15.544653\n",
      "driving_days                 12.182530\n",
      "dtype: float64\n",
      "\n",
      "Null rows outliers:\n",
      " ID                                   0.0\n",
      "label                                  0\n",
      "sessions                         12533.0\n",
      "drives                           10234.0\n",
      "total_sessions              17058.856068\n",
      "n_days_after_onboarding              0.0\n",
      "total_navigations_fav1           22229.0\n",
      "total_navigations_fav2            6038.0\n",
      "driven_km_drives           345809.778548\n",
      "duration_minutes_drives    223741.512669\n",
      "activity_days                        0.0\n",
      "driving_days                       287.0\n",
      "device                                 0\n",
      "dtype: object\n",
      "\n",
      "Non-null rows outliers:\n",
      " ID                                    0.0\n",
      "label                                   0\n",
      "sessions                         233359.0\n",
      "drives                           191460.0\n",
      "total_sessions              391115.642888\n",
      "n_days_after_onboarding               0.0\n",
      "total_navigations_fav1           417906.0\n",
      "total_navigations_fav2           129569.0\n",
      "driven_km_drives           7261416.928366\n",
      "duration_minutes_drives    4168586.847663\n",
      "activity_days                         0.0\n",
      "driving_days                       4573.0\n",
      "device                                  0\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Import packages for data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset into dataframe\n",
    "df = pd.read_csv('waze_dataset.csv')\n",
    "\n",
    "# Isolate rows with null values\n",
    "null_rows = df[df['label'].isnull()]\n",
    "\n",
    "# Isolate rows with non-null values\n",
    "non_null_rows = df[df['label'].notnull()]\n",
    "\n",
    "# Display summary stats of rows with null values\n",
    "#print(f'\\nNull:\\n {null_rows.describe()}')\n",
    "\n",
    "# Display summary stats of rows with non-null values\n",
    "#print(f'\\nNon-null:\\n {non_null_rows.describe()}')\n",
    "\n",
    "# Dùng NumPy boolean indexing để tìm outliers của null_rows\n",
    "null_rows_mean = null_rows.mean()\n",
    "null_rows_std = null_rows.std()\n",
    "null_rows_outliers = null_rows[np.abs(null_rows - null_rows_mean) > 2 * null_rows_std]\n",
    "\n",
    "# Dùng NumPy boolean indexing để tìm outliers của non_null_rows\n",
    "non_null_rows_mean = non_null_rows.mean()\n",
    "non_null_rows_std = non_null_rows.std()\n",
    "non_null_rows_outliers = non_null_rows[np.abs(non_null_rows - non_null_rows_mean) > 2 * non_null_rows_std]\n",
    "\n",
    "# So sánh 2 nhóm Null và Non-null (tìm điểm khác biệt về mean, outliers rồi đánh giá)\n",
    "print(f'\\nNull rows mean:\\n{null_rows_mean}')\n",
    "print(f'\\nNon-null rows mean:\\n{non_null_rows_mean}')\n",
    "print(f'\\nNull rows outliers:\\n {null_rows_outliers.sum()}') \n",
    "print(f'\\nNon-null rows outliers:\\n {non_null_rows_outliers.sum()}') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sJpXfBZUlWC5"
   },
   "source": [
    "ĐÁNH GIÁ:\n",
    "Về Mean (Trung bình):\n",
    "Hai nhóm có sự chênh lệch nhỏ, nhưng Non-null nhỉnh hơn ở các chỉ số liên quan đến thời gian sử dụng và mức độ hoạt động.\n",
    "\n",
    "Về Outliers (Giá trị cực trị):\n",
    "Non-null vượt trội hơn rất nhiều với các giá trị cực trị cao gấp hàng chục lần.\n",
    "Điều này cho thấy nhóm Non-null đa dạng hơn về hành vi người dùng và chứa nhiều người dùng tích cực hơn.\n",
    "\n",
    "Giải Thích Khả Thi:\n",
    "Nhóm Null có thể bao gồm người dùng ít hoạt động hơn hoặc dữ liệu bị thiếu sót.\n",
    "Nhóm Non-null cho thấy rõ ràng hơn về những người dùng trung thành và hoạt động mạnh."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S2CupDgSlpm4"
   },
   "source": [
    "### **Task 2d. Null values - device counts**\n",
    "\n",
    "Next, check the two populations with respect to the `device` variable.\n",
    "\n",
    "**Question:** How many iPhone users had null values and how many Android users had null values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IbCnokO8lsq3",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Số lượng iPhone null rows: 447\n",
      "\n",
      "Số lượng Android null rows: 253\n"
     ]
    }
   ],
   "source": [
    "# Import packages for data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset into dataframe\n",
    "df = pd.read_csv('waze_dataset.csv')\n",
    "\n",
    "# Lọc các hàng mà 'label' bị null và thiết bị là iPhone\n",
    "iphone_null_rows = df[(df['device'] == 'iPhone') & (df['label'].isnull())]\n",
    "\n",
    "# Lọc các hàng mà 'label' bị null và thiết bị là Android\n",
    "android_null_rows = df[(df['device'] == 'Android') & (df['label'].isnull())]\n",
    "\n",
    "# Đếm số lượng người dùng bị null trên từng loại thiết bị\n",
    "print(f'\\nSố lượng iPhone null rows: {len(iphone_null_rows)}')\n",
    "print(f'\\nSố lượng Android null rows: {len(android_null_rows)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JKfLfQQUltQk"
   },
   "source": [
    "KẾT QUẢ:\n",
    "Số lượng iPhone null rows: 447\n",
    "Số lượng Android null rows: 253"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xodMNO1Ql5PZ"
   },
   "source": [
    "Now, of the rows with null values, calculate the percentage with each device&mdash;Android and iPhone. You can do this directly with the [`value_counts()`](https://pandas.pydata.org/docs/reference/api/pandas.Series.value_counts.html) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ajlCljYHmCTa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Device null percentage:\n",
      "iPhone     63.86\n",
      "Android    36.14\n",
      "Name: device, dtype: float64\n",
      "\n",
      "Device null percentage:\n",
      "iPhone: 63.86\n",
      "Android: 36.14\n"
     ]
    }
   ],
   "source": [
    "# Calculate % of iPhone nulls and Android nulls\n",
    "# Import packages for data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset into dataframe\n",
    "df = pd.read_csv('waze_dataset.csv')\n",
    "\n",
    "# Lọc các hàng mà 'label' bị null và thiết bị là iPhone\n",
    "iphone_null_rows = df[(df['device'] == 'iPhone') & (df['label'].isnull())]\n",
    "\n",
    "# Lọc các hàng mà 'label' bị null và thiết bị là Android\n",
    "android_null_rows = df[(df['device'] == 'Android') & (df['label'].isnull())]\n",
    "\n",
    "# Lọc các hàng có 'label' bị null\n",
    "null_rows = df[df['label'].isnull()]\n",
    "\n",
    "# Tính phần trăm số lượng từng loại device trong nhóm null bằng hàm value_counts()\n",
    "null_device_percentage = null_rows['device'].value_counts(normalize=True).round(4) * 100\n",
    "print(f'\\nDevice null percentage:\\n{null_device_percentage}')\n",
    "\n",
    "# Cách khác (cơ bản hơn)\n",
    "ip_null_device_percentage = round(((len(iphone_null_rows)) / (len(null_rows))) *100,2)\n",
    "andr_null_device_percentage = round(((len(android_null_rows)) / (len(null_rows))) *100,2)\n",
    "print(f'\\nDevice null percentage:\\niPhone: {ip_null_device_percentage}\\nAndroid: {andr_null_device_percentage}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dA_ps_fA3xn9"
   },
   "source": [
    "How does this compare to the device ratio in the full dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dm-qKyQNmCsQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iPhone: 64.48%\n",
      "Android: 35.52%\n"
     ]
    }
   ],
   "source": [
    "# Calculate % of iPhone users and Android users in full dataset\n",
    "total_rows = len(df)\n",
    "iphone_percentage = round((len(df[df['device'] == 'iPhone']) / total_rows) * 100, 2)\n",
    "android_percentage = round((len(df[df['device'] == 'Android']) / total_rows) * 100, 2)\n",
    "\n",
    "print(f'iPhone: {iphone_percentage}%')\n",
    "print(f'Android: {android_percentage}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eEIeGZdgmRh9"
   },
   "source": [
    "ĐÁNH GIÁ:\n",
    "Tỷ lệ iPhone và Android trong nhóm null và toàn dataset gần như tương đồng:\n",
    "    iPhone: Chênh lệch 0.62% (64.48% tổng dataset vs. 63.86% trong nhóm null).\n",
    "    Android: Chênh lệch 0.62% (35.52% tổng dataset vs. 36.14% trong nhóm null).\n",
    "Không có sự chênh lệch đáng kể về tỷ lệ thiết bị giữa hai nhóm:\n",
    "    Cả hai nhóm (null và toàn bộ dataset) đều có tỷ lệ iPhone và Android gần giống nhau.\n",
    "    Điều này cho thấy rằng loại thiết bị không phải là yếu tố chính ảnh hưởng đến dữ liệu bị thiếu (null trong label)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uIzg4fXtmSTe"
   },
   "source": [
    "Examine the counts and percentages of users who churned vs. those who were retained. How many of each group are represented in the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zQ1mu8g9maYX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Non-null percentage:\n",
      "retained    82.0\n",
      "churned     18.0\n",
      "Name: label, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Import packages for data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset into dataframe\n",
    "df = pd.read_csv('waze_dataset.csv')\n",
    "\n",
    "# Lọc các hàng mà 'label' là non-null (gồm giá trị 'churned' và 'retained')\n",
    "non_null_rows = df[df['label'].notnull()]\n",
    "\n",
    "# Tính phần trăm số lượng từng loại trong nhóm non-null của cột 'label' bằng hàm value_counts()\n",
    "non_null_percentage = non_null_rows['label'].value_counts(normalize=True).round(2) * 100\n",
    "print(f'\\nNon-null percentage:\\n{non_null_percentage}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VYTZIIOKmfIz"
   },
   "source": [
    "This dataset contains 82% retained users and 18% churned users.\n",
    "\n",
    "Next, compare the medians of each variable for churned and retained users. The reason for calculating the median and not the mean is that you don't want outliers to unduly affect the portrayal of a typical user. Notice, for example, that the maximum value in the `driven_km_drives` column is 21,183 km. That's more than half the circumference of the earth!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jzngebHRmmFA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "retained_df_median: ID                         7509.000000\n",
      "sessions                     56.000000\n",
      "drives                       47.000000\n",
      "total_sessions              157.586756\n",
      "n_days_after_onboarding    1843.000000\n",
      "total_navigations_fav1       68.000000\n",
      "total_navigations_fav2        9.000000\n",
      "driven_km_drives           3464.684614\n",
      "duration_minutes_drives    1458.046141\n",
      "activity_days                17.000000\n",
      "driving_days                 14.000000\n",
      "dtype: float64\n",
      "\n",
      "churned_df_median: ID                         7477.500000\n",
      "sessions                     59.000000\n",
      "drives                       50.000000\n",
      "total_sessions              164.339042\n",
      "n_days_after_onboarding    1321.000000\n",
      "total_navigations_fav1       84.500000\n",
      "total_navigations_fav2       11.000000\n",
      "driven_km_drives           3652.655666\n",
      "duration_minutes_drives    1607.183785\n",
      "activity_days                 8.000000\n",
      "driving_days                  6.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Import packages for data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset into dataframe\n",
    "df = pd.read_csv('waze_dataset.csv')\n",
    "\n",
    "# Phân tách dữ liệu thành hai dataframe: 'Retained' và 'Churned''\n",
    "retained_df = df[df['label'] == 'retained']\n",
    "churned_df = df[df['label'] == 'churned']\n",
    "print(f'\\nretained_df_median: {retained_df.median()}')\n",
    "print(f'\\nchurned_df_median: {churned_df.median()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NvnPFKS3mm71"
   },
   "source": [
    "This offers an interesting snapshot of the two groups, churned vs. retained:\n",
    "\n",
    "Users who churned averaged ~3 more drives in the last month than retained users, but retained users used the app on over twice as many days as churned users in the same time period.\n",
    "\n",
    "The median churned user drove ~200 more kilometers and 2.5 more hours during the last month than the median retained user.\n",
    "\n",
    "It seems that churned users had more drives in fewer days, and their trips were farther and longer in duration. Perhaps this is suggestive of a user profile. Continue exploring!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cUAkU-JInALK"
   },
   "source": [
    "Calculate the median kilometers per drive in the last month for both retained and churned users.\n",
    "\n",
    "Begin by dividing the `driven_km_drives` column by the `drives` column. Then, group the results by churned/retained and calculate the median km/drive of each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TVcP2PPhnBMZ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "churned     74.109416\n",
       "retained    75.014702\n",
       "Name: km_per_drive, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import packages for data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset into dataframe\n",
    "df = pd.read_csv('waze_dataset.csv')\n",
    "\n",
    "# Add a column to df called `km_per_drive`\n",
    "df['km_per_drive'] = df['driven_km_drives'] / df['drives']\n",
    "\n",
    "# Group by `label`, calculate the median, and isolate for km per drive\n",
    "df.groupby('label')['km_per_drive'].median(numeric_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C6VicaRVnFzq"
   },
   "source": [
    "The median retained user drove about one more kilometer per drive than the median churned user. How many kilometers per driving day was this?\n",
    "\n",
    "To calculate this statistic, repeat the steps above using `driving_days` instead of `drives`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I6lD33kfnGQb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "churned     697.541999\n",
       "retained    289.549333\n",
       "Name: km_per_driving_day, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import packages for data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset into dataframe\n",
    "df = pd.read_csv('waze_dataset.csv')\n",
    "\n",
    "# Add a column to df called `km_per_driving_day`\n",
    "df['km_per_driving_day'] = df['driven_km_drives'] / df['driving_days']\n",
    "\n",
    "# Group by `label`, calculate the median, and isolate for km per driving day\n",
    "df.groupby('label')['km_per_driving_day'].median(numeric_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kIfSmukAnVSs"
   },
   "source": [
    "Now, calculate the median number of drives per driving day for each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VAHqOO8endWX"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "churned     10.0000\n",
       "retained     4.0625\n",
       "Name: drives_per_driving_day, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import packages for data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset into dataframe\n",
    "df = pd.read_csv('waze_dataset.csv')\n",
    "\n",
    "# Add a column to df called `drives_per_driving_day`\n",
    "df['drives_per_driving_day'] = df['drives'] / df['driving_days']\n",
    "\n",
    "# Group by `label`, calculate the median, and isolate for drives per driving day\n",
    "df.groupby('label')['drives_per_driving_day'].median(numeric_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LVRAwsb1nv2L"
   },
   "source": [
    "The median user who churned drove 698 kilometers each day they drove last month, which is almost ~240% the per-drive-day distance of retained users. The median churned user had a similarly disproporionate number of drives per drive day compared to retained users.\n",
    "\n",
    "It is clear from these figures that, regardless of whether a user churned or not, the users represented in this data are serious drivers! It would probably be safe to assume that this data does not represent typical drivers at large. Perhaps the data&mdash;and in particular the sample of churned users&mdash;contains a high proportion of long-haul truckers.\n",
    "\n",
    "In consideration of how much these users drive, it would be worthwhile to recommend to Waze that they gather more data on these super-drivers. It's possible that the reason for their driving so much is also the reason why the Waze app does not meet their specific set of needs, which may differ from the needs of a more typical driver, such as a commuter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xc7Q6elLoD1R"
   },
   "source": [
    "Finally, examine whether there is an imbalance in how many users churned by device type.\n",
    "\n",
    "Begin by getting the overall counts of each device type for each group, churned and retained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LGkODIILoEp-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Retained_device_user:\n",
      "iPhone     7580\n",
      "Android    4183\n",
      "Name: device, dtype: int64\n",
      "\n",
      "Churned_device_user:\n",
      "iPhone     1645\n",
      "Android     891\n",
      "Name: device, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Import packages for data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset into dataframe\n",
    "df = pd.read_csv('waze_dataset.csv')\n",
    "\n",
    "# Phân tách dữ liệu thành hai dataframe: 'Retained' và 'Churned''\n",
    "retained_df = df[df['label'] == 'retained']\n",
    "churned_df = df[df['label'] == 'churned']\n",
    "\n",
    "# For each label, calculate the number of Android users and iPhone users\n",
    "print(f\"\\nRetained_device_user:\\n{retained_df['device'].value_counts()}\")\n",
    "print(f\"\\nChurned_device_user:\\n{churned_df['device'].value_counts()}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yTVM6qFkoJs4"
   },
   "source": [
    "Now, within each group, churned and retained, calculate what percent was Android and what percent was iPhone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rx0ElsS6oO7y"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Retained_device_rate:\n",
      "iPhone     64.0\n",
      "Android    36.0\n",
      "Name: device, dtype: float64\n",
      "\n",
      "Churned_device_rate:\n",
      "iPhone     65.0\n",
      "Android    35.0\n",
      "Name: device, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Import packages for data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset into dataframe\n",
    "df = pd.read_csv('waze_dataset.csv')\n",
    "\n",
    "# Phân tách dữ liệu thành hai dataframe: 'Retained' và 'Churned''\n",
    "retained_df = df[df['label'] == 'retained']\n",
    "churned_df = df[df['label'] == 'churned']\n",
    "\n",
    "# For each label, calculate the percentage of Android users and iPhone users\n",
    "print(f\"\\nRetained_device_rate:\\n{retained_df['device'].value_counts(normalize=True).round(2)*100}\")\n",
    "print(f\"\\nChurned_device_rate:\\n{churned_df['device'].value_counts(normalize=True).round(2)*100}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DQVIMPzroavO"
   },
   "source": [
    "The ratio of iPhone users and Android users is consistent between the churned group and the retained group, and those ratios are both consistent with the ratio found in the overall dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tF_82VLgzrQm"
   },
   "source": [
    "<img src=\"images/Construct.png\" width=\"100\" height=\"100\" align=left>\n",
    "\n",
    "## **PACE: Construct**\n",
    "\n",
    "**Note**: The Construct stage does not apply to this workflow. The PACE framework can be adapted to fit the specific requirements of any project.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BMHV86A6zrQo"
   },
   "source": [
    "<img src=\"images/Execute.png\" width=\"100\" height=\"100\" align=left>\n",
    "\n",
    "## **PACE: Execute**\n",
    "\n",
    "Consider the questions in your PACE Strategy Document and those below to craft your response:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u3HxcMZgz6iW"
   },
   "source": [
    "### **Task 3. Conclusion**\n",
    "\n",
    "Recall that your supervisor, May Santer, asked you to share your findings with the data team in an executive summary. Consider the following questions as you prepare to write your summary. Think about key points you may want to share with the team, and what information is most relevant to the user churn project.\n",
    "\n",
    "**Questions:**\n",
    "\n",
    "1. Did the data contain any missing values? How many, and which variables were affected? Was there a pattern to the missing data?\n",
    "\n",
    "2. What is a benefit of using the median value of a sample instead of the mean?\n",
    "\n",
    "3. Did your investigation give rise to further questions that you would like to explore or ask the Waze team about?\n",
    "\n",
    "4. What percentage of the users in the dataset were Android users and what percentage were iPhone users?\n",
    "\n",
    "5. What were some distinguishing characteristics of users who churned vs. users who were retained?\n",
    "\n",
    "6. Was there an appreciable difference in churn rate between iPhone users vs. Android users?\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iMHlK7k5_2PV"
   },
   "source": [
    "1. Missing Values trong Dataset\n",
    "Cột label là cột duy nhất bị thiếu, với 700 giá trị null.\n",
    "Các cột khác không có giá trị thiếu.\n",
    "Không có mẫu (pattern) rõ ràng nào về missing data trong các cột khác, nên vấn đề tập trung ở cột label.\n",
    "\n",
    "2. Lợi ích của việc sử dụng giá trị trung vị (median) thay vì trung bình (mean)?\n",
    "Median ít bị ảnh hưởng bởi các giá trị cực trị (outliers).\n",
    "Trong dataset, ví dụ như cột driven_km_drives có giá trị tối đa lên đến 21,183 km, là một giá trị rất lớn và dễ làm lệch giá trị mean. Nếu dùng median, ta sẽ có một đại diện chính xác hơn cho \"người dùng điển hình\".\n",
    "\n",
    "3. Trong quá trình phân tích, có câu hỏi nào khác cần đặt ra với nhóm Waze không?\n",
    "Tại sao một số người dùng có hoạt động rất tích cực nhưng vẫn churn (rời bỏ)?\n",
    "Liệu có yếu tố về khu vực địa lý, thời gian sử dụng ứng dụng hoặc phiên bản ứng dụng liên quan đến churn không?\n",
    "Có chiến lược nào đang được áp dụng để giữ chân người dùng có activity_days thấp không?\n",
    "Những người dùng đã từng churn có bao giờ quay lại sử dụng ứng dụng không?\n",
    "\n",
    "4. Tỷ lệ Người Dùng Android và iPhone\n",
    "iPhone: 64.48%\n",
    "Android: 35.52%\n",
    "Điều này cho thấy phần lớn người dùng trong dataset là iPhone.\n",
    "\n",
    "5. Đặc điểm khác biệt giữa người dùng churn và retained là gì?\n",
    "Retained users:\n",
    "Có thời gian sử dụng lâu hơn (n_days_after_onboarding median là 1843 ngày vs. 1321 ngày ở churned).\n",
    "Tần suất hoạt động cao hơn (activity_days và driving_days cao gấp đôi so với churned users).\n",
    "Hoạt động đều đặn và duy trì lâu dài với ứng dụng.\n",
    "\n",
    "Churned users:\n",
    "Có xu hướng sử dụng nhiều hơn trong ngắn hạn, như số phiên (sessions), số lần lái xe (drives) và điều hướng (total_navigations_fav1 và fav2) đều cao hơn.\n",
    "Tuy nhiên, số ngày hoạt động thực tế lại ít hơn và thời gian gắn bó ngắn hơn.\n",
    "\n",
    "6. Có sự khác biệt đáng kể nào về tỷ lệ churn rate giữa người dùng iPhone và Android không?\n",
    "Tỷ lệ người dùng iPhone và Android trong hai nhóm gần như tương đương, với sự chênh lệch chỉ 1%.\n",
    "\n",
    "iPhone: Tăng từ 64% (retained) lên 65% (churned).\n",
    "Android: Giảm từ 36% (retained) xuống 35% (churned).\n",
    "\n",
    "Kết luận sơ bộ:\n",
    "Sự khác biệt chỉ 1% là không đáng kể về mặt thống kê.\n",
    "Điều này cho thấy loại thiết bị không phải là yếu tố chính gây ra churn.\n",
    "Người dùng iPhone và Android có retain rate và churn rate rất đồng đều, phản ánh rằng churn xảy ra ngẫu nhiên hơn là bị ảnh hưởng bởi loại thiết bị."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Congratulations!** You've completed this lab. However, you may not notice a green check mark next to this item on Coursera's platform. Please continue your progress regardless of the check mark. Just click on the \"save\" icon at the top of this notebook to ensure your work has been logged."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "11e8ZirEhEEhZj7pNZmB8r_dPDEwRnfPR",
     "timestamp": 1671051831339
    },
    {
     "file_id": "1SoZM3Yq8C8BdYu-st3_BAlhze2_Z6Ilb",
     "timestamp": 1668798742100
    },
    {
     "file_id": "1U6q6WFOo7_Ka_C9cdq49KwAsI_lFX86-",
     "timestamp": 1668698832849
    },
    {
     "file_id": "1h6rKqbyzegmvnh5T6X1MhTFOXE6VUciq",
     "timestamp": 1666209449412
    },
    {
     "file_id": "1Vz66UR_ImIhJ4HEkCzdY_9E9QLKiboV1",
     "timestamp": 1663780048645
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
